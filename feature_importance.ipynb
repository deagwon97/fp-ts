{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('deep': conda)",
   "display_name": "Python 3.8.5 64-bit ('deep': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e3dd400f5d87c1a87f15209f9ca1847d91223dd67820b2a3322b88f3be052679"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "import importlib\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1015)\n",
    "# define 'device' to upload tensor in gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 상위 폴더에서 module을 import하기 위해 시스템 경로에 상위 폴더의 경로를 추가\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "\n",
    "from utils.preprocess_utils import *\n",
    "from utils.train_utils import *\n",
    "from train_morning.models.model_cycle.cycle_lstm import LSTMModel_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "all use\n10 Epochs train MSE: 0.02888 // valid MSE: 0.01917\n20 Epochs train MSE: 0.02249 // valid MSE: 0.01341\n30 Epochs train MSE: 0.02229 // valid MSE: 0.01281\n40 Epochs train MSE: 0.02090 // valid MSE: 0.01221\n50 Epochs train MSE: 0.02025 // valid MSE: 0.01218\n60 Epochs train MSE: 0.01960 // valid MSE: 0.01200\n70 Epochs train MSE: 0.01846 // valid MSE: 0.01161\n80 Epochs train MSE: 0.01619 // valid MSE: 0.01072\n90 Epochs train MSE: 0.01381 // valid MSE: 0.00944\n100 Epochs train MSE: 0.01251 // valid MSE: 0.00889\n110 Epochs train MSE: 0.01151 // valid MSE: 0.00858\n120 Epochs train MSE: 0.01064 // valid MSE: 0.00825\n130 Epochs train MSE: 0.00956 // valid MSE: 0.00772\n140 Epochs train MSE: 0.00874 // valid MSE: 0.00726\n150 Epochs train MSE: 0.00804 // valid MSE: 0.00723\n160 Epochs train MSE: 0.00751 // valid MSE: 0.00707\n170 Epochs train MSE: 0.00719 // valid MSE: 0.00719\n180 Epochs train MSE: 0.00663 // valid MSE: 0.00682\n190 Epochs train MSE: 0.00632 // valid MSE: 0.00664\n200 Epochs train MSE: 0.00622 // valid MSE: 0.00688\n210 Epochs train MSE: 0.00591 // valid MSE: 0.00661\n220 Epochs train MSE: 0.00577 // valid MSE: 0.00658\n230 Epochs train MSE: 0.00564 // valid MSE: 0.00663\n240 Epochs train MSE: 0.00562 // valid MSE: 0.00663\n250 Epochs train MSE: 0.00546 // valid MSE: 0.00673\n260 Epochs train MSE: 0.00534 // valid MSE: 0.00674\n270 Epochs train MSE: 0.00531 // valid MSE: 0.00665\n280 Epochs train MSE: 0.00520 // valid MSE: 0.00670\n290 Epochs train MSE: 0.00517 // valid MSE: 0.00693\n300 Epochs train MSE: 0.00483 // valid MSE: 0.00681\n310 Epochs train MSE: 0.00463 // valid MSE: 0.00666\n320 Epochs train MSE: 0.00441 // valid MSE: 0.00665\n330 Epochs train MSE: 0.00412 // valid MSE: 0.00677\n340 Epochs train MSE: 0.00407 // valid MSE: 0.00669\n350 Epochs train MSE: 0.00369 // valid MSE: 0.00672\n360 Epochs train MSE: 0.00360 // valid MSE: 0.00682\n370 Epochs train MSE: 0.00348 // valid MSE: 0.00679\n380 Epochs train MSE: 0.00338 // valid MSE: 0.00682\n390 Epochs train MSE: 0.00331 // valid MSE: 0.00677\n"
    }
   ],
   "source": [
    "\n",
    "print('all use')\n",
    "\n",
    "with open('data/preprocess/l_data_list.pkl', 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "data_list = append_cycle_size(data_list)\n",
    "train_time, train_notime, train_y,\\\n",
    "valid_time, valid_notime, valid_y, \\\n",
    "    test_time, test_notime, test_y = data_list\n",
    "    \n",
    "train_time, train_notime, train_y,\\\n",
    "valid_time, valid_notime, valid_y, \\\n",
    "    test_time, test_notime, test_y    = numpy2tensor(data_list)\n",
    "\n",
    "\n",
    "model= LSTMModel_cycle(input_size = 12, hidden_size = 32, no_time_size =4).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "criterion = nn.MSELoss(size_average = True)\n",
    "\n",
    "train_error = []\n",
    "valid_error = []\n",
    "hist = {'best_val_error': 100,\n",
    "        'best_val_epoch': 0}\n",
    "\n",
    "num_epochs = 400\n",
    "for t in range(0, num_epochs):\n",
    "    train_pred = model(train_time, train_notime)\n",
    "    loss = criterion(train_pred, train_y[:,:,1])\n",
    "    train_error.append(loss)\n",
    "    valid_pred = model(valid_time, valid_notime)\n",
    "    valid_mse = float(criterion(valid_pred, valid_y[:,:,1]).cpu())\n",
    "    valid_error.append(valid_mse)\n",
    "    if hist['best_val_error'] >= valid_mse:\n",
    "        hist['best_val_error'] = valid_mse\n",
    "        hist['best_val_epoch'] = t\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(f\"{t} Epochs train MSE: {loss.item():1.5f} // valid MSE: {valid_mse:1.5f}\")\n",
    "        \n",
    "valid_errors.append(hist['best_val_error'])\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_time의 12개 채널 정보\n",
    "# 'card_use', 'holiday', 'day_corona',\n",
    "# 'ondo', 'subdo', 'rain_snow',\n",
    "# 'dayofyear_sin', 'dayofyear_cos', 'weekday_sin', 'weekday_cos',\n",
    "# 'flow_trend', flow_cycle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = ['card_use', 'holiday', 'day_corona','ondo', 'subdo',\n",
    "                 'rain_snow','dayofyear_sin', 'dayofyear_cos', 'weekday_sin',\n",
    "                  'weekday_cos', 'flow_trend', 'flow_cycle', 'ALL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    features_name  valid_errors\n0        card_use      0.005314\n1         holiday      0.004789\n2      day_corona      0.005328\n3            ondo      0.006173\n4           subdo      0.005097\n5       rain_snow      0.005050\n6   dayofyear_sin      0.005409\n7   dayofyear_cos      0.005255\n8     weekday_sin      0.005182\n9     weekday_cos      0.005360\n10     flow_trend      0.005469\n11     flow_cycle      0.017196\n12            ALL      0.006500",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>features_name</th>\n      <th>valid_errors</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>card_use</td>\n      <td>0.005314</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>holiday</td>\n      <td>0.004789</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>day_corona</td>\n      <td>0.005328</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ondo</td>\n      <td>0.006173</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subdo</td>\n      <td>0.005097</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>rain_snow</td>\n      <td>0.005050</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>dayofyear_sin</td>\n      <td>0.005409</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>dayofyear_cos</td>\n      <td>0.005255</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>weekday_sin</td>\n      <td>0.005182</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>weekday_cos</td>\n      <td>0.005360</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>flow_trend</td>\n      <td>0.005469</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>flow_cycle</td>\n      <td>0.017196</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>ALL</td>\n      <td>0.006500</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pd.DataFrame({'features_name' : features_name,\n",
    "                'valid_errors': valid_errors})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "chs train MSE: 0.01909 // valid MSE: 0.01154\n60 Epochs train MSE: 0.01725 // valid MSE: 0.01085\n70 Epochs train MSE: 0.01571 // valid MSE: 0.01033\n80 Epochs train MSE: 0.01439 // valid MSE: 0.00982\n90 Epochs train MSE: 0.01311 // valid MSE: 0.00914\n100 Epochs train MSE: 0.01196 // valid MSE: 0.00854\n110 Epochs train MSE: 0.01068 // valid MSE: 0.00814\n120 Epochs train MSE: 0.00974 // valid MSE: 0.00776\n130 Epochs train MSE: 0.00886 // valid MSE: 0.00736\n140 Epochs train MSE: 0.00788 // valid MSE: 0.00702\n150 Epochs train MSE: 0.00724 // valid MSE: 0.00683\n160 Epochs train MSE: 0.00596 // valid MSE: 0.00611\n170 Epochs train MSE: 0.00536 // valid MSE: 0.00585\n180 Epochs train MSE: 0.00488 // valid MSE: 0.00568\n190 Epochs train MSE: 0.00451 // valid MSE: 0.00570\n200 Epochs train MSE: 0.00422 // valid MSE: 0.00563\n210 Epochs train MSE: 0.00395 // valid MSE: 0.00561\n220 Epochs train MSE: 0.00377 // valid MSE: 0.00565\n230 Epochs train MSE: 0.00347 // valid MSE: 0.00560\n240 Epochs train MSE: 0.00325 // valid MSE: 0.00557\n250 Epochs train MSE: 0.00306 // valid MSE: 0.00555\n260 Epochs train MSE: 0.00288 // valid MSE: 0.00540\n270 Epochs train MSE: 0.00274 // valid MSE: 0.00541\n280 Epochs train MSE: 0.00260 // valid MSE: 0.00543\n290 Epochs train MSE: 0.00252 // valid MSE: 0.00556\n300 Epochs train MSE: 0.00244 // valid MSE: 0.00550\n310 Epochs train MSE: 0.00235 // valid MSE: 0.00550\n320 Epochs train MSE: 0.00228 // valid MSE: 0.00549\n330 Epochs train MSE: 0.00228 // valid MSE: 0.00546\n340 Epochs train MSE: 0.00224 // valid MSE: 0.00549\n350 Epochs train MSE: 0.00215 // valid MSE: 0.00545\n360 Epochs train MSE: 0.00209 // valid MSE: 0.00548\n370 Epochs train MSE: 0.00216 // valid MSE: 0.00562\n380 Epochs train MSE: 0.00205 // valid MSE: 0.00551\n390 Epochs train MSE: 0.00199 // valid MSE: 0.00552\n3\n10 Epochs train MSE: 0.02989 // valid MSE: 0.01598\n20 Epochs train MSE: 0.02323 // valid MSE: 0.01380\n30 Epochs train MSE: 0.02227 // valid MSE: 0.01349\n40 Epochs train MSE: 0.02127 // valid MSE: 0.01264\n50 Epochs train MSE: 0.02063 // valid MSE: 0.01233\n60 Epochs train MSE: 0.01979 // valid MSE: 0.01196\n70 Epochs train MSE: 0.01786 // valid MSE: 0.01157\n80 Epochs train MSE: 0.01618 // valid MSE: 0.01114\n90 Epochs train MSE: 0.01492 // valid MSE: 0.01053\n100 Epochs train MSE: 0.01369 // valid MSE: 0.00989\n110 Epochs train MSE: 0.01195 // valid MSE: 0.00927\n120 Epochs train MSE: 0.01016 // valid MSE: 0.00854\n130 Epochs train MSE: 0.00908 // valid MSE: 0.00838\n140 Epochs train MSE: 0.00847 // valid MSE: 0.00831\n150 Epochs train MSE: 0.00801 // valid MSE: 0.00817\n160 Epochs train MSE: 0.00767 // valid MSE: 0.00796\n170 Epochs train MSE: 0.00735 // valid MSE: 0.00778\n180 Epochs train MSE: 0.00702 // valid MSE: 0.00759\n190 Epochs train MSE: 0.00667 // valid MSE: 0.00733\n200 Epochs train MSE: 0.00635 // valid MSE: 0.00719\n210 Epochs train MSE: 0.00609 // valid MSE: 0.00700\n220 Epochs train MSE: 0.00580 // valid MSE: 0.00685\n230 Epochs train MSE: 0.00556 // valid MSE: 0.00662\n240 Epochs train MSE: 0.00524 // valid MSE: 0.00649\n250 Epochs train MSE: 0.00506 // valid MSE: 0.00634\n260 Epochs train MSE: 0.00493 // valid MSE: 0.00635\n270 Epochs train MSE: 0.00483 // valid MSE: 0.00640\n280 Epochs train MSE: 0.00474 // valid MSE: 0.00641\n290 Epochs train MSE: 0.00471 // valid MSE: 0.00648\n300 Epochs train MSE: 0.00461 // valid MSE: 0.00644\n310 Epochs train MSE: 0.00457 // valid MSE: 0.00644\n320 Epochs train MSE: 0.00449 // valid MSE: 0.00652\n330 Epochs train MSE: 0.00441 // valid MSE: 0.00654\n340 Epochs train MSE: 0.00440 // valid MSE: 0.00664\n350 Epochs train MSE: 0.00436 // valid MSE: 0.00658\n360 Epochs train MSE: 0.00424 // valid MSE: 0.00656\n370 Epochs train MSE: 0.00416 // valid MSE: 0.00656\n380 Epochs train MSE: 0.00404 // valid MSE: 0.00655\n390 Epochs train MSE: 0.00387 // valid MSE: 0.00649\n4\n10 Epochs train MSE: 0.02518 // valid MSE: 0.01518\n20 Epochs train MSE: 0.02307 // valid MSE: 0.01424\n30 Epochs train MSE: 0.02074 // valid MSE: 0.01259\n40 Epochs train MSE: 0.01871 // valid MSE: 0.01179\n50 Epochs train MSE: 0.01700 // valid MSE: 0.01129\n60 Epochs train MSE: 0.01545 // valid MSE: 0.01078\n70 Epochs train MSE: 0.01397 // valid MSE: 0.01023\n80 Epochs train MSE: 0.01260 // valid MSE: 0.00972\n90 Epochs train MSE: 0.01120 // valid MSE: 0.00912\n100 Epochs train MSE: 0.01004 // valid MSE: 0.00824\n110 Epochs train MSE: 0.00925 // valid MSE: 0.00790\n120 Epochs train MSE: 0.00866 // valid MSE: 0.00759\n130 Epochs train MSE: 0.00824 // valid MSE: 0.00736\n140 Epochs train MSE: 0.00788 // valid MSE: 0.00712\n150 Epochs train MSE: 0.00754 // valid MSE: 0.00693\n160 Epochs train MSE: 0.00715 // valid MSE: 0.00674\n170 Epochs train MSE: 0.00667 // valid MSE: 0.00663\n180 Epochs train MSE: 0.00606 // valid MSE: 0.00642\n190 Epochs train MSE: 0.00537 // valid MSE: 0.00598\n200 Epochs train MSE: 0.00491 // valid MSE: 0.00565\n210 Epochs train MSE: 0.00433 // valid MSE: 0.00548\n220 Epochs train MSE: 0.00378 // valid MSE: 0.00523\n230 Epochs train MSE: 0.00351 // valid MSE: 0.00516\n240 Epochs train MSE: 0.00326 // valid MSE: 0.00517\n250 Epochs train MSE: 0.00306 // valid MSE: 0.00519\n260 Epochs train MSE: 0.00319 // valid MSE: 0.00542\n270 Epochs train MSE: 0.00290 // valid MSE: 0.00529\n280 Epochs train MSE: 0.00271 // valid MSE: 0.00526\n290 Epochs train MSE: 0.00263 // valid MSE: 0.00525\n300 Epochs train MSE: 0.00254 // valid MSE: 0.00526\n310 Epochs train MSE: 0.00248 // valid MSE: 0.00534\n320 Epochs train MSE: 0.00241 // valid MSE: 0.00539\n330 Epochs train MSE: 0.00235 // valid MSE: 0.00545\n340 Epochs train MSE: 0.00242 // valid MSE: 0.00554\n350 Epochs train MSE: 0.00230 // valid MSE: 0.00553\n360 Epochs train MSE: 0.00222 // valid MSE: 0.00565\n370 Epochs train MSE: 0.00218 // valid MSE: 0.00573\n380 Epochs train MSE: 0.00214 // valid MSE: 0.00575\n390 Epochs train MSE: 0.00211 // valid MSE: 0.00580\n5\n10 Epochs train MSE: 0.02390 // valid MSE: 0.01553\n20 Epochs train MSE: 0.02332 // valid MSE: 0.01415\n30 Epochs train MSE: 0.02170 // valid MSE: 0.01291\n40 Epochs train MSE: 0.02036 // valid MSE: 0.01253\n50 Epochs train MSE: 0.01921 // valid MSE: 0.01207\n60 Epochs train MSE: 0.01779 // valid MSE: 0.01120\n70 Epochs train MSE: 0.01686 // valid MSE: 0.01081\n80 Epochs train MSE: 0.01608 // valid MSE: 0.01053\n90 Epochs train MSE: 0.01500 // valid MSE: 0.01032\n100 Epochs train MSE: 0.01391 // valid MSE: 0.00975\n110 Epochs train MSE: 0.01322 // valid MSE: 0.00951\n120 Epochs train MSE: 0.01270 // valid MSE: 0.00930\n130 Epochs train MSE: 0.01211 // valid MSE: 0.00915\n140 Epochs train MSE: 0.01114 // valid MSE: 0.00861\n150 Epochs train MSE: 0.00981 // valid MSE: 0.00793\n160 Epochs train MSE: 0.00874 // valid MSE: 0.00743\n170 Epochs train MSE: 0.00762 // valid MSE: 0.00670\n180 Epochs train MSE: 0.00645 // valid MSE: 0.00606\n190 Epochs train MSE: 0.00576 // valid MSE: 0.00577\n200 Epochs train MSE: 0.00520 // valid MSE: 0.00552\n210 Epochs train MSE: 0.00473 // valid MSE: 0.00532\n220 Epochs train MSE: 0.00435 // valid MSE: 0.00515\n230 Epochs train MSE: 0.00409 // valid MSE: 0.00516\n240 Epochs train MSE: 0.00384 // valid MSE: 0.00518\n250 Epochs train MSE: 0.00375 // valid MSE: 0.00535\n260 Epochs train MSE: 0.00351 // valid MSE: 0.00519\n270 Epochs train MSE: 0.00336 // valid MSE: 0.00542\n280 Epochs train MSE: 0.00322 // valid MSE: 0.00548\n290 Epochs train MSE: 0.00311 // valid MSE: 0.00555\n300 Epochs train MSE: 0.00309 // valid MSE: 0.00552\n310 Epochs train MSE: 0.00295 // valid MSE: 0.00554\n320 Epochs train MSE: 0.00288 // valid MSE: 0.00569\n330 Epochs train MSE: 0.00281 // valid MSE: 0.00551\n340 Epochs train MSE: 0.00281 // valid MSE: 0.00554\n350 Epochs train MSE: 0.00268 // valid MSE: 0.00555\n360 Epochs train MSE: 0.00264 // valid MSE: 0.00559\n370 Epochs train MSE: 0.00266 // valid MSE: 0.00543\n380 Epochs train MSE: 0.00255 // valid MSE: 0.00555\n390 Epochs train MSE: 0.00251 // valid MSE: 0.00566\n6\n10 Epochs train MSE: 0.02709 // valid MSE: 0.01732\n20 Epochs train MSE: 0.02213 // valid MSE: 0.01354\n30 Epochs train MSE: 0.01928 // valid MSE: 0.01196\n40 Epochs train MSE: 0.01702 // valid MSE: 0.01117\n50 Epochs train MSE: 0.01420 // valid MSE: 0.00989\n60 Epochs train MSE: 0.01266 // valid MSE: 0.00912\n70 Epochs train MSE: 0.01137 // valid MSE: 0.00839\n80 Epochs train MSE: 0.01009 // valid MSE: 0.00765\n90 Epochs train MSE: 0.00871 // valid MSE: 0.00693\n100 Epochs train MSE: 0.00787 // valid MSE: 0.00660\n110 Epochs train MSE: 0.00688 // valid MSE: 0.00605\n120 Epochs train MSE: 0.00632 // valid MSE: 0.00595\n130 Epochs train MSE: 0.00586 // valid MSE: 0.00584\n140 Epochs train MSE: 0.00548 // valid MSE: 0.00577\n150 Epochs train MSE: 0.00514 // valid MSE: 0.00568\n160 Epochs train MSE: 0.00493 // valid MSE: 0.00559\n170 Epochs train MSE: 0.00470 // valid MSE: 0.00577\n180 Epochs train MSE: 0.00446 // valid MSE: 0.00549\n190 Epochs train MSE: 0.00425 // valid MSE: 0.00551\n200 Epochs train MSE: 0.00409 // valid MSE: 0.00549\n210 Epochs train MSE: 0.00398 // valid MSE: 0.00546\n220 Epochs train MSE: 0.00384 // valid MSE: 0.00557\n230 Epochs train MSE: 0.00375 // valid MSE: 0.00546\n240 Epochs train MSE: 0.00362 // valid MSE: 0.00551\n250 Epochs train MSE: 0.00360 // valid MSE: 0.00545\n260 Epochs train MSE: 0.00351 // valid MSE: 0.00554\n270 Epochs train MSE: 0.00337 // valid MSE: 0.00556\n280 Epochs train MSE: 0.00331 // valid MSE: 0.00551\n290 Epochs train MSE: 0.00351 // valid MSE: 0.00544\n300 Epochs train MSE: 0.00327 // valid MSE: 0.00542\n310 Epochs train MSE: 0.00318 // valid MSE: 0.00544\n320 Epochs train MSE: 0.00311 // valid MSE: 0.00548\n330 Epochs train MSE: 0.00306 // valid MSE: 0.00558\n340 Epochs train MSE: 0.00300 // valid MSE: 0.00552\n350 Epochs train MSE: 0.00322 // valid MSE: 0.00546\n360 Epochs train MSE: 0.00308 // valid MSE: 0.00545\n370 Epochs train MSE: 0.00291 // valid MSE: 0.00550\n380 Epochs train MSE: 0.00287 // valid MSE: 0.00551\n390 Epochs train MSE: 0.00282 // valid MSE: 0.00551\n7\n10 Epochs train MSE: 0.03403 // valid MSE: 0.02192\n20 Epochs train MSE: 0.02433 // valid MSE: 0.01350\n30 Epochs train MSE: 0.02246 // valid MSE: 0.01318\n40 Epochs train MSE: 0.01908 // valid MSE: 0.01204\n50 Epochs train MSE: 0.01553 // valid MSE: 0.01018\n60 Epochs train MSE: 0.01340 // valid MSE: 0.00928\n70 Epochs train MSE: 0.01150 // valid MSE: 0.00824\n80 Epochs train MSE: 0.00984 // valid MSE: 0.00750\n90 Epochs train MSE: 0.00847 // valid MSE: 0.00694\n100 Epochs train MSE: 0.00706 // valid MSE: 0.00659\n110 Epochs train MSE: 0.00561 // valid MSE: 0.00628\n120 Epochs train MSE: 0.00454 // valid MSE: 0.00592\n130 Epochs train MSE: 0.00401 // valid MSE: 0.00566\n140 Epochs train MSE: 0.00364 // valid MSE: 0.00542\n150 Epochs train MSE: 0.00338 // valid MSE: 0.00536\n160 Epochs train MSE: 0.00316 // valid MSE: 0.00541\n170 Epochs train MSE: 0.00297 // valid MSE: 0.00533\n180 Epochs train MSE: 0.00282 // valid MSE: 0.00534\n190 Epochs train MSE: 0.00269 // valid MSE: 0.00534\n200 Epochs train MSE: 0.00257 // valid MSE: 0.00533\n210 Epochs train MSE: 0.00255 // valid MSE: 0.00538\n220 Epochs train MSE: 0.00241 // valid MSE: 0.00531\n230 Epochs train MSE: 0.00235 // valid MSE: 0.00538\n240 Epochs train MSE: 0.00227 // valid MSE: 0.00539\n250 Epochs train MSE: 0.00229 // valid MSE: 0.00542\n260 Epochs train MSE: 0.00216 // valid MSE: 0.00535\n270 Epochs train MSE: 0.00212 // valid MSE: 0.00536\n280 Epochs train MSE: 0.00206 // valid MSE: 0.00536\n290 Epochs train MSE: 0.00215 // valid MSE: 0.00541\n300 Epochs train MSE: 0.00203 // valid MSE: 0.00540\n310 Epochs train MSE: 0.00200 // valid MSE: 0.00528\n320 Epochs train MSE: 0.00193 // valid MSE: 0.00541\n330 Epochs train MSE: 0.00190 // valid MSE: 0.00542\n340 Epochs train MSE: 0.00188 // valid MSE: 0.00541\n350 Epochs train MSE: 0.00185 // valid MSE: 0.00544\n360 Epochs train MSE: 0.00183 // valid MSE: 0.00546\n370 Epochs train MSE: 0.00203 // valid MSE: 0.00562\n380 Epochs train MSE: 0.00183 // valid MSE: 0.00549\n390 Epochs train MSE: 0.00178 // valid MSE: 0.00548\n8\n10 Epochs train MSE: 0.03437 // valid MSE: 0.02110\n20 Epochs train MSE: 0.02534 // valid MSE: 0.01556\n30 Epochs train MSE: 0.02383 // valid MSE: 0.01406\n40 Epochs train MSE: 0.02292 // valid MSE: 0.01382\n50 Epochs train MSE: 0.02178 // valid MSE: 0.01304\n60 Epochs train MSE: 0.02075 // valid MSE: 0.01247\n70 Epochs train MSE: 0.01979 // valid MSE: 0.01197\n80 Epochs train MSE: 0.01852 // valid MSE: 0.01146\n90 Epochs train MSE: 0.01625 // valid MSE: 0.01078\n100 Epochs train MSE: 0.01313 // valid MSE: 0.01024\n110 Epochs train MSE: 0.01058 // valid MSE: 0.00910\n120 Epochs train MSE: 0.00867 // valid MSE: 0.00824\n130 Epochs train MSE: 0.00740 // valid MSE: 0.00734\n140 Epochs train MSE: 0.00647 // valid MSE: 0.00693\n150 Epochs train MSE: 0.00564 // valid MSE: 0.00661\n160 Epochs train MSE: 0.00503 // valid MSE: 0.00622\n170 Epochs train MSE: 0.00443 // valid MSE: 0.00575\n180 Epochs train MSE: 0.00393 // valid MSE: 0.00533\n190 Epochs train MSE: 0.00356 // valid MSE: 0.00534\n200 Epochs train MSE: 0.00325 // valid MSE: 0.00532\n210 Epochs train MSE: 0.00307 // valid MSE: 0.00534\n220 Epochs train MSE: 0.00300 // valid MSE: 0.00545\n230 Epochs train MSE: 0.00284 // valid MSE: 0.00546\n240 Epochs train MSE: 0.00269 // valid MSE: 0.00546\n250 Epochs train MSE: 0.00258 // valid MSE: 0.00540\n260 Epochs train MSE: 0.00251 // valid MSE: 0.00540\n270 Epochs train MSE: 0.00258 // valid MSE: 0.00547\n280 Epochs train MSE: 0.00238 // valid MSE: 0.00540\n290 Epochs train MSE: 0.00233 // valid MSE: 0.00541\n300 Epochs train MSE: 0.00226 // valid MSE: 0.00539\n310 Epochs train MSE: 0.00231 // valid MSE: 0.00545\n320 Epochs train MSE: 0.00217 // valid MSE: 0.00537\n330 Epochs train MSE: 0.00212 // valid MSE: 0.00533\n340 Epochs train MSE: 0.00208 // valid MSE: 0.00534\n350 Epochs train MSE: 0.00203 // valid MSE: 0.00530\n360 Epochs train MSE: 0.00219 // valid MSE: 0.00535\n370 Epochs train MSE: 0.00211 // valid MSE: 0.00532\n380 Epochs train MSE: 0.00198 // valid MSE: 0.00518\n390 Epochs train MSE: 0.00193 // valid MSE: 0.00531\n9\n10 Epochs train MSE: 0.03224 // valid MSE: 0.02070\n20 Epochs train MSE: 0.02268 // valid MSE: 0.01405\n30 Epochs train MSE: 0.02150 // valid MSE: 0.01294\n40 Epochs train MSE: 0.02068 // valid MSE: 0.01226\n50 Epochs train MSE: 0.02000 // valid MSE: 0.01198\n60 Epochs train MSE: 0.01961 // valid MSE: 0.01186\n70 Epochs train MSE: 0.01911 // valid MSE: 0.01165\n80 Epochs train MSE: 0.01828 // valid MSE: 0.01135\n90 Epochs train MSE: 0.01604 // valid MSE: 0.01033\n100 Epochs train MSE: 0.01413 // valid MSE: 0.00922\n110 Epochs train MSE: 0.01256 // valid MSE: 0.00866\n120 Epochs train MSE: 0.01114 // valid MSE: 0.00820\n130 Epochs train MSE: 0.00989 // valid MSE: 0.00763\n140 Epochs train MSE: 0.00891 // valid MSE: 0.00740\n150 Epochs train MSE: 0.00804 // valid MSE: 0.00700\n160 Epochs train MSE: 0.00735 // valid MSE: 0.00680\n170 Epochs train MSE: 0.00674 // valid MSE: 0.00660\n180 Epochs train MSE: 0.00642 // valid MSE: 0.00631\n190 Epochs train MSE: 0.00592 // valid MSE: 0.00615\n200 Epochs train MSE: 0.00545 // valid MSE: 0.00599\n210 Epochs train MSE: 0.00505 // valid MSE: 0.00575\n220 Epochs train MSE: 0.00509 // valid MSE: 0.00586\n230 Epochs train MSE: 0.00456 // valid MSE: 0.00541\n240 Epochs train MSE: 0.00430 // valid MSE: 0.00545\n250 Epochs train MSE: 0.00409 // valid MSE: 0.00538\n260 Epochs train MSE: 0.00391 // valid MSE: 0.00540\n270 Epochs train MSE: 0.00376 // valid MSE: 0.00543\n280 Epochs train MSE: 0.00366 // valid MSE: 0.00540\n290 Epochs train MSE: 0.00354 // valid MSE: 0.00556\n300 Epochs train MSE: 0.00345 // valid MSE: 0.00550\n310 Epochs train MSE: 0.00332 // valid MSE: 0.00558\n320 Epochs train MSE: 0.00331 // valid MSE: 0.00562\n330 Epochs train MSE: 0.00321 // valid MSE: 0.00555\n340 Epochs train MSE: 0.00316 // valid MSE: 0.00556\n350 Epochs train MSE: 0.00305 // valid MSE: 0.00560\n360 Epochs train MSE: 0.00303 // valid MSE: 0.00562\n370 Epochs train MSE: 0.00294 // valid MSE: 0.00561\n380 Epochs train MSE: 0.00290 // valid MSE: 0.00562\n390 Epochs train MSE: 0.00299 // valid MSE: 0.00573\n10\n10 Epochs train MSE: 0.03023 // valid MSE: 0.01873\n20 Epochs train MSE: 0.02244 // valid MSE: 0.01351\n30 Epochs train MSE: 0.02174 // valid MSE: 0.01285\n40 Epochs train MSE: 0.02038 // valid MSE: 0.01193\n50 Epochs train MSE: 0.01975 // valid MSE: 0.01174\n60 Epochs train MSE: 0.01894 // valid MSE: 0.01157\n70 Epochs train MSE: 0.01781 // valid MSE: 0.01108\n80 Epochs train MSE: 0.01670 // valid MSE: 0.01051\n90 Epochs train MSE: 0.01521 // valid MSE: 0.00996\n100 Epochs train MSE: 0.01390 // valid MSE: 0.00940\n110 Epochs train MSE: 0.01317 // valid MSE: 0.00916\n120 Epochs train MSE: 0.01195 // valid MSE: 0.00857\n130 Epochs train MSE: 0.01046 // valid MSE: 0.00796\n140 Epochs train MSE: 0.00965 // valid MSE: 0.00767\n150 Epochs train MSE: 0.00907 // valid MSE: 0.00764\n160 Epochs train MSE: 0.00862 // valid MSE: 0.00774\n170 Epochs train MSE: 0.00826 // valid MSE: 0.00791\n180 Epochs train MSE: 0.00797 // valid MSE: 0.00793\n190 Epochs train MSE: 0.00771 // valid MSE: 0.00793\n200 Epochs train MSE: 0.00754 // valid MSE: 0.00801\n210 Epochs train MSE: 0.00725 // valid MSE: 0.00785\n220 Epochs train MSE: 0.00699 // valid MSE: 0.00775\n230 Epochs train MSE: 0.00665 // valid MSE: 0.00757\n240 Epochs train MSE: 0.00621 // valid MSE: 0.00747\n250 Epochs train MSE: 0.00552 // valid MSE: 0.00695\n260 Epochs train MSE: 0.00491 // valid MSE: 0.00653\n270 Epochs train MSE: 0.00452 // valid MSE: 0.00628\n280 Epochs train MSE: 0.00416 // valid MSE: 0.00606\n290 Epochs train MSE: 0.00372 // valid MSE: 0.00613\n300 Epochs train MSE: 0.00332 // valid MSE: 0.00567\n310 Epochs train MSE: 0.00303 // valid MSE: 0.00552\n320 Epochs train MSE: 0.00288 // valid MSE: 0.00553\n330 Epochs train MSE: 0.00278 // valid MSE: 0.00557\n340 Epochs train MSE: 0.00269 // valid MSE: 0.00561\n350 Epochs train MSE: 0.00272 // valid MSE: 0.00559\n360 Epochs train MSE: 0.00257 // valid MSE: 0.00570\n370 Epochs train MSE: 0.00252 // valid MSE: 0.00580\n380 Epochs train MSE: 0.00246 // valid MSE: 0.00574\n390 Epochs train MSE: 0.00241 // valid MSE: 0.00584\n11\n10 Epochs train MSE: 0.48307 // valid MSE: 0.31225\n20 Epochs train MSE: 0.26502 // valid MSE: 0.23069\n30 Epochs train MSE: 0.12842 // valid MSE: 0.13161\n40 Epochs train MSE: 0.06813 // valid MSE: 0.07047\n50 Epochs train MSE: 0.04489 // valid MSE: 0.04436\n60 Epochs train MSE: 0.03758 // valid MSE: 0.03249\n70 Epochs train MSE: 0.03327 // valid MSE: 0.02770\n80 Epochs train MSE: 0.03086 // valid MSE: 0.02597\n90 Epochs train MSE: 0.02909 // valid MSE: 0.02493\n100 Epochs train MSE: 0.02809 // valid MSE: 0.02564\n110 Epochs train MSE: 0.02666 // valid MSE: 0.02280\n120 Epochs train MSE: 0.02587 // valid MSE: 0.02192\n130 Epochs train MSE: 0.02526 // valid MSE: 0.02432\n140 Epochs train MSE: 0.02485 // valid MSE: 0.02063\n150 Epochs train MSE: 0.02377 // valid MSE: 0.02084\n160 Epochs train MSE: 0.02342 // valid MSE: 0.02038\n170 Epochs train MSE: 0.02270 // valid MSE: 0.02043\n180 Epochs train MSE: 0.02215 // valid MSE: 0.02125\n190 Epochs train MSE: 0.02352 // valid MSE: 0.01916\n200 Epochs train MSE: 0.02159 // valid MSE: 0.02142\n210 Epochs train MSE: 0.02104 // valid MSE: 0.02017\n220 Epochs train MSE: 0.02072 // valid MSE: 0.01968\n230 Epochs train MSE: 0.02028 // valid MSE: 0.01981\n240 Epochs train MSE: 0.02063 // valid MSE: 0.01879\n250 Epochs train MSE: 0.02010 // valid MSE: 0.02113\n260 Epochs train MSE: 0.01942 // valid MSE: 0.01915\n270 Epochs train MSE: 0.01917 // valid MSE: 0.01879\n280 Epochs train MSE: 0.01888 // valid MSE: 0.01932\n290 Epochs train MSE: 0.01875 // valid MSE: 0.01824\n300 Epochs train MSE: 0.02192 // valid MSE: 0.01817\n310 Epochs train MSE: 0.01855 // valid MSE: 0.01828\n320 Epochs train MSE: 0.01809 // valid MSE: 0.01862\n330 Epochs train MSE: 0.01781 // valid MSE: 0.01830\n340 Epochs train MSE: 0.01763 // valid MSE: 0.01790\n350 Epochs train MSE: 0.01739 // valid MSE: 0.01836\n360 Epochs train MSE: 0.02006 // valid MSE: 0.02338\n370 Epochs train MSE: 0.01729 // valid MSE: 0.01925\n380 Epochs train MSE: 0.01730 // valid MSE: 0.01736\n390 Epochs train MSE: 0.01688 // valid MSE: 0.01832\n"
    }
   ],
   "source": [
    "valid_errors = []\n",
    "for feature_idx in range(12):\n",
    "    print(feature_idx)\n",
    "    # load model\n",
    "    features = [idx for idx in range(12)]\n",
    "    features.pop(feature_idx)\n",
    "\n",
    "    with open('data/preprocess/l_data_list.pkl', 'rb') as f:\n",
    "        data_list = pickle.load(f)\n",
    "\n",
    "    data_list = append_cycle_size(data_list)\n",
    "    train_time, train_notime, train_y,\\\n",
    "    valid_time, valid_notime, valid_y, \\\n",
    "        test_time, test_notime, test_y = data_list\n",
    "        \n",
    "    data_list = [train_time[:,:,features], train_notime, train_y,\\\n",
    "                valid_time[:,:,features], valid_notime, valid_y, \\\n",
    "                test_time[:,:,features], test_notime, test_y]\n",
    "        \n",
    "    train_time, train_notime, train_y,\\\n",
    "    valid_time, valid_notime, valid_y, \\\n",
    "        test_time, test_notime, test_y    = numpy2tensor(data_list)\n",
    "\n",
    "\n",
    "    model= LSTMModel_cycle(input_size = 11, hidden_size = 32, no_time_size =4).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-2)\n",
    "    criterion = nn.MSELoss(size_average = True)\n",
    "\n",
    "    train_error = []\n",
    "    valid_error = []\n",
    "    hist = {'best_val_error': 100,\n",
    "            'best_val_epoch': 0}\n",
    "\n",
    "    num_epochs = 400\n",
    "    for t in range(0, num_epochs):\n",
    "        train_pred = model(train_time, train_notime)\n",
    "        loss = criterion(train_pred, train_y[:,:,1])\n",
    "        train_error.append(loss)\n",
    "        valid_pred = model(valid_time, valid_notime)\n",
    "        valid_mse = float(criterion(valid_pred, valid_y[:,:,1]).cpu())\n",
    "        valid_error.append(valid_mse)\n",
    "        if hist['best_val_error'] >= valid_mse:\n",
    "            hist['best_val_error'] = valid_mse\n",
    "            hist['best_val_epoch'] = t\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if t % 10 == 0 and t !=0:\n",
    "            print(f\"{t} Epochs train MSE: {loss.item():1.5f} // valid MSE: {valid_mse:1.5f}\")\n",
    "            \n",
    "    valid_errors.append(hist['best_val_error'])\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}