{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600846648968",
   "display_name": "Python 3.8.5 64-bit ('deep': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "import importlib\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torch.optim as optim\n",
    "torch.manual_seed(1015)\n",
    "# define 'device' to upload tensor in gpu\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# 상위 폴더에서 module을 import하기 위해 시스템 경로에 상위 폴더의 경로를 추가\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "\n",
    "from utils.preprocess_utils import *\n",
    "from utils.train_utils import *\n",
    "from models.model_cycle.cycle_lstm import LSTMModel_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### morning data\n",
    "with open('../data/preprocess/l_data_list.pkl', 'rb') as f:\n",
    "#with open('data/preprocess/l_data_list.pkl', 'rb') as f:\n",
    "#with open('data/preprocess/e_data_list.pkl', 'rb') as f:\n",
    "#with open('data/preprocess/full_data_list.pkl', 'rb') as f:\n",
    "    data_list = pickle.load(f)\n",
    "\n",
    "#print(data_list[1].shape)\n",
    "data_list = append_cycle_size(data_list)\n",
    "#print(data_list[1].shape)\n",
    "\n",
    "train_time, train_notime, train_y,\\\n",
    "valid_time, valid_notime, valid_y, \\\n",
    "    test_time, test_notime, test_y = numpy2tensor(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = LSTMModel_cycle(input_size = 10, hidden_size = 32, no_time_size = 4).to(device)\n",
    "# set model\n",
    "criterion = nn.MSELoss(size_average = True)\n",
    "\n",
    "\n",
    "train_error = []\n",
    "valid_error = []\n",
    "\n",
    "hist = {'best_val_error': 100,\n",
    "        'best_val_epoch': 0}\n",
    "start_epochs = 0\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "10 Epochs train MSE: 0.01798 // valid MSE: 0.01037\n20 Epochs train MSE: 0.01790 // valid MSE: 0.01031\n30 Epochs train MSE: 0.01769 // valid MSE: 0.01010\n40 Epochs train MSE: 0.01721 // valid MSE: 0.00981\n50 Epochs train MSE: 0.01626 // valid MSE: 0.00943\n60 Epochs train MSE: 0.01409 // valid MSE: 0.00901\n70 Epochs train MSE: 0.01075 // valid MSE: 0.00809\n80 Epochs train MSE: 0.00764 // valid MSE: 0.00621\n90 Epochs train MSE: 0.00555 // valid MSE: 0.00571\n"
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.5e-2)\n",
    "\n",
    "run_epochs = 100\n",
    "num_epochs += run_epochs\n",
    "for t in range(start_epochs, num_epochs):\n",
    "    # Initialise hidden state\n",
    "    # Don't do this if you want your LSTM to be stateful\n",
    "    # model.hidden = model.init_hidden()  \n",
    "    # Forward pass\n",
    "\n",
    "    train_pred = model(train_time, train_notime)\n",
    "    loss = criterion(train_pred, train_y[:,:,1])\n",
    "    train_error.append(loss)\n",
    "\n",
    "    valid_pred = model(valid_time, valid_notime)\n",
    "    valid_mse = float(criterion(valid_pred, valid_y[:,:,1]).cpu())\n",
    "    valid_error.append(valid_mse)\n",
    "\n",
    "    # Zero out gradient, else they will accumulate between epochs\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    if hist['best_val_error'] >= valid_mse:\n",
    "        hist['best_val_error'] = valid_mse\n",
    "        hist['best_val_epoch'] = t\n",
    "        best_model = model\n",
    "\n",
    "    if t % 10 == 0 and t !=0:\n",
    "        print(f\"{t} Epochs train MSE: {loss.item():1.5f} // valid MSE: {valid_mse:1.5f}\")\n",
    "\n",
    "start_epochs = num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}