{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1600337753611",
   "display_name": "Python 3.8.5 64-bit ('deep': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(69, 241, 13)"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "time_data = pd.read_csv('data/original/time_data.txt', sep  = ' ') \n",
    "time_data = df2npy(time_data)\n",
    "\n",
    "# 아침 점심 저녁 분리\n",
    "morning_data = time_data[:,2,:,:]\n",
    "morning_data[:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (69,234,13) into shape (69,235,13)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6f641e2b052a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# tend, cycle 추가\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmorning_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappend_trend_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmorning_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlunch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappend_trend_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlunch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mevening_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mappend_trend_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevening_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-61a6133d8ed8>\u001b[0m in \u001b[0;36mappend_trend_cycle\u001b[1;34m(time_data)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mappend_trend_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtime_data_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLOC_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDATE_SIZE\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mROLLSIZE\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURE_SIZE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mtime_data_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mROLLSIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;31m# trend, cycle 순서로 return\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mtime_data_new\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msplit_trend_cycle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# flow_pop의 index는 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (69,234,13) into shape (69,235,13)"
     ]
    }
   ],
   "source": [
    "# tend, cycle 추가\n",
    "morning_data = append_trend_cycle(morning_data)\n",
    "lunch_data = append_trend_cycle(lunch_data)\n",
    "evening_data = append_trend_cycle(evening_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constant\n",
    "LOC_SIZE = 69\n",
    "TIME_SIZE = 3\n",
    "DATE_SIZE = 241\n",
    "FEATURE_SIZE = 13\n",
    "#set window size\n",
    "INPUT_WINDOW = 20\n",
    "OUTPUT_WINDOW = 7\n",
    "ROLLSIZE = 7\n",
    "\n",
    "def seq2cycle(seq):\n",
    "    return pd.Series(seq).rolling(ROLLSIZE).mean()\n",
    "\n",
    "# flow_tot -> flow_trend + flow_cycle 분리\n",
    "def split_trend_cycle(flow_pop):\n",
    "    new_flow_pop = np.zeros([LOC_SIZE, flow_pop.shape[1] - (ROLLSIZE-1), 2])\n",
    "\n",
    "    for loc in range(LOC_SIZE):\n",
    "        new_flow_pop[loc,:, 0] = seq2cycle(flow_pop[loc,:])[ROLLSIZE-1:]\n",
    "        new_flow_pop[loc,:, 1] = flow_pop[loc, ROLLSIZE-1:] - new_flow_pop[loc,:, 0]\n",
    "    print(new_flow_pop)\n",
    "    return new_flow_pop\n",
    "\n",
    "def append_trend_cycle(time_data):\n",
    "    time_data_new = np.empty([LOC_SIZE, DATE_SIZE - (ROLLSIZE-1), FEATURE_SIZE + 2])\n",
    "    time_data_new[:,:,:-2] = time_data[:,ROLLSIZE:,:]\n",
    "    # trend, cycle 순서로 return\n",
    "    time_data_new[:,:,-2:] = split_trend_cycle(time_data[:,:,2])# flow_pop의 index는 2\n",
    "    return time_data_new\n",
    "\n",
    "def df2npy(time_data):\n",
    "    # make loc_list(dong code)\n",
    "    loc_list = list(time_data.HDONG_CD.unique())\n",
    "\n",
    "    # select features\n",
    "    time_data = time_data[['flow_pop', 'HDONG_CD', 'time',\n",
    "                        'card_use', 'holiday', 'day_corona', 'ondo', 'subdo',\n",
    "                        'rain_snow', 'STD_YMD']]\n",
    "\n",
    "    # change string time to int time\n",
    "    time_data.time[time_data.time == 'morning'] = 0 # morning\n",
    "    time_data.time[time_data.time == 'lunch'] = 1 # lunch\n",
    "    time_data.time[time_data.time == 'evening'] = 2 # evening\n",
    "\n",
    "    # to datetime\n",
    "    time_data.STD_YMD = pd.to_datetime(time_data.STD_YMD)\n",
    "\n",
    "    # make dayofyear weekday\n",
    "    time_data['dayofyear'] = time_data.STD_YMD.dt.dayofyear\n",
    "    time_data['weekday'] = time_data.STD_YMD.dt.weekday\n",
    "    time_data['dayofyear_sin'] = np.sin(2 * np.pi * (time_data['dayofyear'])/365)\n",
    "    time_data['dayofyear_cos'] = np.cos(2 * np.pi * (time_data['dayofyear'])/365)\n",
    "    time_data['weekday_sin'] = np.sin(2 * np.pi * (time_data['weekday'])/7)# 월화수목금토일\n",
    "    time_data['weekday_cos'] = np.cos(2 * np.pi * (time_data['weekday'])/7)\n",
    "\n",
    "    # reselect features\n",
    "    time_data = time_data[['HDONG_CD', 'time','flow_pop',\n",
    "                        'card_use', 'holiday', 'day_corona', 'ondo', 'subdo',\n",
    "                        'rain_snow', 'dayofyear_sin', 'dayofyear_cos', 'weekday_sin', 'weekday_cos']]\n",
    "\n",
    "    # table -> matrix\n",
    "    time_data = np.array(time_data).reshape(LOC_SIZE, TIME_SIZE, DATE_SIZE, FEATURE_SIZE)# 지역, 시간, 날짜, features\n",
    "    return time_data\n",
    "\n",
    "def scaleing_time(data, scaler = None):\n",
    "    shape = data.shape\n",
    "    data = data.reshape(-1, shape[-1])\n",
    "    if scaler == None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaler, scaled_data.reshape(shape)\n",
    "\n",
    "def scaleing_no_time(data, scaler = None):\n",
    "    df_index = data.index\n",
    "    df_columns = data.columns\n",
    "    if scaler == None:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(data.values.reshape(-1,data.shape[-1]))\n",
    "    data = scaler.transform(data.values.reshape(-1,data.shape[-1]))\n",
    "    data = pd.DataFrame(data, index = df_index, columns = df_columns)\n",
    "    return scaler, data\n",
    "\n",
    "def split_train_valid_test(time_data):\n",
    "    # make_random \n",
    "    loc_index = [i for i in range(69)]\n",
    "    random.seed(1015)\n",
    "    random.shuffle(loc_index)\n",
    "\n",
    "    # split time data\n",
    "    train_time = time_data[loc_index[ :55], :201, :]\n",
    "    valid_time_1 = time_data[loc_index[ :55], 201 -INPUT_WINDOW : -20, :] # train 지역& valid 기간\n",
    "    valid_time_2 = time_data[loc_index[55:62], : -20, :] # valid 지역 & (train + valid) 기간\n",
    "    test_time_1 = time_data[loc_index[:62], 221 -INPUT_WINDOW : , :] # train,valid 지역& test 기간\n",
    "    test_time_2 = time_data[loc_index[62:], :, :] # test 지역 & (train + valid + test) 기간\n",
    "\n",
    "    # set loc index\n",
    "    train_loc_index = list(set(train_time[:,0,0].astype(np.int64)))\n",
    "    valid_loc_index = list(set(valid_time_2[:,0,0].astype(np.int64)))\n",
    "    test_loc_index = list(set(test_time_2[:,0,0].astype(np.int64)))\n",
    "\n",
    "    #scaling - time # 지역별 스케일링\n",
    "    time_scaler, train_time[:,:,2:] = scaleing_time(train_time[:,:,2:])\n",
    "    _, valid_time_1[:,:,2:] = scaleing_time(valid_time_1[:,:,2:], time_scaler)\n",
    "    _, valid_time_2[:,:,2:] = scaleing_time(valid_time_2[:,:,2:], time_scaler)\n",
    "    _, test_time_1[:,:,2:] = scaleing_time(test_time_1[:,:,2:], time_scaler)\n",
    "    _, test_time_2[:,:,2:] = scaleing_time(test_time_2[:,:,2:], time_scaler)\n",
    "\n",
    "    train_valid_test = [train_time, valid_time_1, valid_time_2, test_time_1, test_time_2]\n",
    "    train_valid_test_index = [train_loc_index, valid_loc_index, test_loc_index]\n",
    "\n",
    "    return train_valid_test, train_valid_test_index, time_scaler\n",
    "\n",
    "def split_notime_data(nontime_data, train_valid_test_index):\n",
    "    train_loc_index, valid_loc_index, test_loc_index= train_valid_test_index\n",
    "    # make no time data\n",
    "    nontime_data = nontime_data[['HDONG_CD', 'time', 'tot_pop', 'age_80U', 'AREA']]\n",
    "    nontime_data = nontime_data.groupby(['HDONG_CD']).sum()\n",
    "\n",
    "    # split no time data\n",
    "    train_no_time = nontime_data.loc[train_loc_index]\n",
    "    valid_no_time = nontime_data.loc[valid_loc_index]\n",
    "    test_no_time = nontime_data.loc[test_loc_index]\n",
    "\n",
    "    # scaleing no time data*\n",
    "    no_time_scaler, train_no_time = scaleing_no_time(train_no_time)\n",
    "    _,              valid_no_time = scaleing_no_time(valid_no_time)\n",
    "    _,              test_no_time  = scaleing_no_time(test_no_time)\n",
    "\n",
    "    notime = [train_no_time, valid_no_time, test_no_time]\n",
    "    return pd.concat(notime), no_time_scaler\n",
    "\n",
    "def split_sequence(sequence, input_window = 20, output_window = 7, target_index  = 2):\n",
    "    x, y = list(), list()\n",
    "    #print(sequence.shape)\n",
    "    for day in range(sequence.shape[0]):\n",
    "        end_ix = day + input_window\n",
    "        if end_ix > (len(sequence)- output_window) -1:#\n",
    "            break\n",
    "        seq_x, seq_y = sequence[day:end_ix, :], sequence[end_ix:end_ix+output_window, 2]\n",
    "        x.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "def make_time_notime_data(time_data, notime_data, input_window = 20, out_window = 7):\n",
    "    x_time_batch, x_notime_batch, y_batch = list(), list(), list()\n",
    "\n",
    "    x_time = []\n",
    "    x_notime = []\n",
    "    y_time = []\n",
    "\n",
    "    for loc in range(time_data.shape[0]):\n",
    "        loc_code = time_data[loc,0,0]\n",
    "        #print(time_data[loc_code,time_idx,0,0])\n",
    "        x, y = split_sequence(time_data[loc,:,:], input_window, out_window)\n",
    "        notime = notime_data.loc[loc_code]\n",
    "        aug_notime = np.zeros([x.shape[0], notime.shape[0]])\n",
    "        aug_notime[:,:] = notime\n",
    "        \n",
    "        x_time.append(x)\n",
    "        x_notime.append(aug_notime)\n",
    "        y_time.append(y)\n",
    "    \n",
    "    x_time = np.concatenate(x_time)\n",
    "    x_notime = np.concatenate(x_notime)\n",
    "    y_time = np.concatenate(y_time)\n",
    "\n",
    "    print(x_time.shape)\n",
    "    print(x_notime.shape)\n",
    "    print(y_time.shape)\n",
    "\n",
    "    return x_time, x_notime, y_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "time_data = pd.read_csv('data/original/time_data.txt', sep  = ' ') \n",
    "time_data = df2npy(time_data)\n",
    "\n",
    "# 아침 점심 저녁 분리\n",
    "morning_data = time_data[:,2,:,:]\n",
    "lunch_data = time_data[:,1,:,:]\n",
    "evening_data = time_data[:,0,:,:]\n",
    "\n",
    "# tend, cycle 추가\n",
    "morning_data = append_trend_cycle(morning_data)\n",
    "lunch_data = append_trend_cycle(lunch_data)\n",
    "evening_data = append_trend_cycle(evening_data)\n",
    "\n",
    "# train_validation_test split  & scaling\n",
    "morning_data, train_valid_test_loc_index, m_time_scaler = split_train_valid_test(morning_data)\n",
    "# m_time_train, m_time_valid, m_time_test = morning_data\n",
    "lunch_data, _, l_time_scaler = split_train_valid_test(lunch_data)\n",
    "evening_data, _, e_time_scaler = split_train_valid_test(evening_data)\n",
    "\n",
    "nontime_data = pd.read_csv('data/original/nontime_data.txt', sep = ' ')\n",
    "notime, no_time_scaler = split_notime_data(nontime_data, train_valid_test_loc_index)\n",
    "# notime_train, notime_valid, notime_test = notime\n",
    "\n",
    "print('\\n morning')\n",
    "m_train_time, m_train_notime, m_train_y = make_time_notime_data(morning_data[0], notime)\n",
    "m_valid_time, m_valid_notime, m_valid_y = make_time_notime_data(morning_data[1], notime)\n",
    "m_test_time, m_test_notime, m_test_y = make_time_notime_data(morning_data[2], notime)\n",
    "\n",
    "print('\\n lunch')\n",
    "l_train_time, l_train_notime, l_train_y = make_time_notime_data(lunch_data[0], notime)\n",
    "l_valid_time, l_valid_notime, l_valid_y = make_time_notime_data(lunch_data[1], notime)\n",
    "l_test_time, l_test_notime, l_test_y = make_time_notime_data(lunch_data[2], notime)\n",
    "\n",
    "print('\\n evening')\n",
    "e_train_time, e_train_notime, e_train_y = make_time_notime_data(evening_data[0], notime)\n",
    "e_valid_time, e_valid_notime, e_valid_y = make_time_notime_data(evening_data[1], notime)\n",
    "e_test_time, e_test_notime, e_test_y = make_time_notime_data(evening_data[2], notime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}